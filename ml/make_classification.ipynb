{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        delta.probe-0  delta.probe-1  delta.probe-2  delta.probe-3  \\\n",
      "0            1.622315       2.769667       2.723968       1.741097   \n",
      "1            1.954375       2.823065       3.079325       1.859442   \n",
      "2            2.286995       2.925057       3.408145       2.124228   \n",
      "3            2.493395       3.043359       3.613963       2.430442   \n",
      "4            2.631627       3.258771       3.762355       2.656391   \n",
      "...               ...            ...            ...            ...   \n",
      "139334       2.469729       2.367149       2.539648       2.439549   \n",
      "139335       2.263767       2.162679       2.329796       2.230391   \n",
      "139336       1.941438       1.798132       2.003060       1.859764   \n",
      "139337       1.554543       1.289372       1.584606       1.305354   \n",
      "139338       1.129414       0.690161       1.245645       0.766861   \n",
      "\n",
      "        theta.probe-0  theta.probe-1  theta.probe-2  theta.probe-3  \\\n",
      "0            1.827639       2.313439       1.727301       1.537712   \n",
      "1            1.809061       2.174991       1.739320       1.167849   \n",
      "2            1.843203       2.170454       1.631167       1.179789   \n",
      "3            1.904844       2.324345       1.781093       1.515482   \n",
      "4            1.994048       2.526503       1.981874       1.999439   \n",
      "...               ...            ...            ...            ...   \n",
      "139334       2.237215       2.151240       2.309673       2.224785   \n",
      "139335       1.979834       1.892916       2.053904       1.967396   \n",
      "139336       1.560003       1.461185       1.620527       1.521448   \n",
      "139337       1.011122       0.894689       1.044584       0.934123   \n",
      "139338       0.496932       0.356077       0.527319       0.477692   \n",
      "\n",
      "        alpha.probe-0  alpha.probe-1  ...  beta.probe-3  gamma.probe-0  \\\n",
      "0            2.702769       3.275298  ...      3.347379       2.750198   \n",
      "1            2.725520       3.289234  ...      3.375639       2.735247   \n",
      "2            2.738801       3.279205  ...      3.389661       2.700509   \n",
      "3            2.767359       3.266502  ...      3.381204       2.687569   \n",
      "4            2.807161       3.259288  ...      3.354631       2.742387   \n",
      "...               ...            ...  ...           ...            ...   \n",
      "139334       1.454347       1.596825  ...      1.006428       0.708258   \n",
      "139335       1.276910       1.421871  ...      1.082704       0.692852   \n",
      "139336       1.064120       1.173587  ...      1.242058       0.692470   \n",
      "139337       0.923745       0.912699  ...      1.344020       0.684711   \n",
      "139338       0.842747       0.678546  ...      1.364663       0.714929   \n",
      "\n",
      "        gamma.probe-1  gamma.probe-2  gamma.probe-3     timestamp       pid  \\\n",
      "0            3.319111       1.891430       2.773405  1.683055e+12  2a7ba24a   \n",
      "1            3.272096       1.911536       2.745164  1.683055e+12  2a7ba24a   \n",
      "2            3.207049       1.874288       2.691031  1.683055e+12  2a7ba24a   \n",
      "3            3.183106       1.822256       2.661611  1.683055e+12  2a7ba24a   \n",
      "4            3.255980       1.798347       2.719254  1.683055e+12  2a7ba24a   \n",
      "...               ...            ...            ...           ...       ...   \n",
      "139334       1.241880       1.366124       0.921922  1.682456e+12  7848bec2   \n",
      "139335       1.191665       1.324037       0.769377  1.682456e+12  7848bec2   \n",
      "139336       1.151409       1.260925       0.757104  1.682456e+12  7848bec2   \n",
      "139337       1.143490       1.213911       0.886395  1.682456e+12  7848bec2   \n",
      "139338       1.170274       1.269450       1.033876  1.682456e+12  7848bec2   \n",
      "\n",
      "         elo  block_id  solved  \n",
      "0        800         1    True  \n",
      "1        800         1    True  \n",
      "2        800         1    True  \n",
      "3        800         1    True  \n",
      "4        800         1    True  \n",
      "...      ...       ...     ...  \n",
      "139334  1250        90   False  \n",
      "139335  1250        90   False  \n",
      "139336  1250        90   False  \n",
      "139337  1250        90   False  \n",
      "139338  1250        90   False  \n",
      "\n",
      "[139339 rows x 25 columns]\n",
      "count    1282.000000\n",
      "mean        1.017941\n",
      "std         0.807163\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%         2.000000\n",
      "max         2.000000\n",
      "Name: elo, dtype: float64\n",
      "0 - 39 - 1 - 51\n",
      "0 - 54 - 1 - 52\n",
      "0 - 24 - 1 - 23\n",
      "0 - 24 - 1 - 25\n",
      "0 - 34 - 1 - 48\n",
      "0 - 64 - 1 - 55\n",
      "0 - 38 - 1 - 47\n",
      "0 - 37 - 1 - 44\n",
      "0 - 40 - 1 - 30\n",
      "0 - 52 - 1 - 72\n",
      "number of puzzles for 2a7ba24a: 87\n",
      "number of puzzles for 44dd5d31: 116\n",
      "number of puzzles for 1bf79614: 83\n",
      "number of puzzles for cf88d785: 144\n",
      "number of puzzles for 168dd1ac: 141\n",
      "number of puzzles for 7cc59678: 116\n",
      "number of puzzles for 16230396: 120\n",
      "number of puzzles for 5c1034cf: 210\n",
      "number of puzzles for 7848bec2: 85\n",
      "---------------------------------\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'runCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 160\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 160\u001b[0m runCV(all_X, all_y, \u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m, dtype)\n\u001b[1;32m    161\u001b[0m \u001b[39m# run_merf(all_X, all_y, all_P, dtype)    \u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'runCV' is not defined"
     ]
    }
   ],
   "source": [
    "# merf psd 0.7742113806103438\n",
    "# merf after reref to avg mastoids 0.7436573207110183\n",
    "#psd - pid - all - KNeighborsClassifier          - 0.750\n",
    "\n",
    "# TODO: proper regression model, after filter(elo >= 1000 & elo <= 1750) \n",
    "#                                      standardize elo within participant\n",
    "#                                \n",
    "#TODO: ADD OTHER REGRESSORS TO MERF. \n",
    "#TODO: ensure that we have balanced data per participant in training/testing. \n",
    "#TODO: see how hold-one-out participant training works; see if adding some training data per person works. \n",
    " \n",
    "\n",
    "# STUFF TRIED BUT NOT NECESSARY\n",
    "# not doing for stats anymore, so keep em! \n",
    "# drop overall bottom and top 10% of elo\n",
    "# df_mean['elo'] = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile').fit_transform(df_mean['elo'].to_numpy().reshape(-1, 1)).astype(int)\n",
    "# df_mean = df_mean[(df_mean['elo'] != 0) & (df_mean['elo'] != 9)] \n",
    "\n",
    "# # min-max scale all the elos - since we're discretizing, this isn't necessary\n",
    "# elos = df_mean['elo'] \n",
    "# df_mean['elo'] = (elos - elos.min()) / (elos.max() - elos.min())\n",
    "# df_mean['elo'] *= 100\n",
    "# df_mean['elo'] = df_mean['elo'].astype(int)\n",
    "\n",
    "# AVERAGE_PROBES = False\n",
    "\n",
    "#     if AVERAGE_PROBES:\n",
    "#         for wave in ['alpha', 'beta', 'delta', 'theta']:\n",
    "#             df_mean[f\"{wave}_avg\"] = (df_mean[f'{wave}.probe-0'] + df_mean[f'{wave}.probe-1'] + \n",
    "#                                       df_mean[f'{wave}.probe-2'] + df_mean[f'{wave}.probe-3']) / 4\n",
    "#             df_mean[f\"{wave}_sd\"]  = (df_sd[f'{wave}.probe-0'] + df_sd[f'{wave}.probe-1'] +\n",
    "#                                       df_sd[f'{wave}.probe-2'] + df_sd[f'{wave}.probe-3']) / 4\n",
    "            \n",
    "#         df_mean = df_mean.drop(columns = [x for x in df.keys() if 'probe' in x])\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, \\\n",
    "                             AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from merf import MERF\n",
    "from library import *\n",
    "\n",
    "MERF_MAX_ITER = 20\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "NORMALIZE = False\n",
    "\n",
    "Y_STYLE = 'elo'\n",
    "dtype   = \"psd\"\n",
    "\n",
    "df = pd.read_csv(f\"{DBFNAME.split('.csv')[0]}_psd_{FILTNAME}\", dtype = {'pid': str})\n",
    "df = df[df['pid'].notna()]\n",
    "df = df[df['pid'] != \"92511e53\"]    # this guy is WAY better than everyone else; remove his data.\n",
    "\n",
    "PIDS = psd_df['pid'].unique()\n",
    "\n",
    "def extract_features(df):\n",
    "    print(df)\n",
    "\n",
    "    df_mean = df.groupby(['pid', 'block_id']).mean().reset_index()\n",
    "    df_sd = df.groupby(['pid', 'block_id']).std().reset_index()\n",
    " \n",
    "    #print(df_mean)        \n",
    "\n",
    "    # use top and bottom 1/3 of elo for classification\n",
    "    df_mean['elo'] = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile').fit_transform(df_mean['elo'].to_numpy().reshape(-1, 1)).astype(int)\n",
    "    print(df_mean['elo'].describe())\n",
    "    #df_mean = df_mean[(df_mean['elo'] != 1)]\n",
    "    # 2s -> 1s ==> turn to binary\n",
    "    #    df_mean['elo'] = df_mean['elo'].replace(2, 1) \n",
    "  \n",
    "    # split into 7 bins, choose bottom 2 and top 4 => 4/7 => yields 80% accuracy\n",
    "    # df_mean['elo'] = KBinsDiscretizer(n_bins=7, encode='ordinal', strategy='quantile').fit_transform(df_mean['elo'].to_numpy().reshape(-1, 1)).astype(int)\n",
    "    # df_mean = df_mean[(df_mean['elo'] <= 1) | (df_mean['elo'] >= 5)]\n",
    "    # df_mean['elo'] = df_mean['elo'].replace(1, 0)\n",
    "    # df_mean['elo'] = df_mean['elo'].replace(5, 1)\n",
    "    # df_mean['elo'] = df_mean['elo'].replace(6, 1)\n",
    "\n",
    "    # use if we want to add standard deviation\n",
    "    # for key in [k for k in df_sd.keys() if 'probe' in k]:\n",
    "    #     df_mean[key + '.sd'] = df_sd[key]\n",
    "    \n",
    "    df = df_mean\n",
    "\n",
    "    p_dfs = {}\n",
    "    for pid in df['pid'].unique():\n",
    "        p_df = df[df['pid'] == pid].copy().reset_index(drop=True)\n",
    "           \n",
    "        if Y_STYLE == 'elo': p_df['y'] = p_df['elo']\n",
    "        else:                p_df['y'] = p_df['solved']\n",
    "\n",
    "        p_dfs[pid] = p_df #.sample(n=35, replace=False, random_state=RANDOM_STATE) \n",
    "    \n",
    "        print(f\"0 - {sum(p_dfs[pid]['y'] == 0)} - 1 - {sum(p_dfs[pid]['y'] == 1)}\")\n",
    "    return p_dfs\n",
    "    \n",
    "ALL_DFS = extract_features(psd_df)\n",
    "\n",
    "all_X = []\n",
    "all_y = []\n",
    "all_P = []\n",
    "for i, p in enumerate(PIDS):\n",
    "\n",
    "    \n",
    "    print(f\"number of puzzles for {p}: {len(ALL_DFS[p])}\")\n",
    "    \n",
    "    p_subset_df = ALL_DFS[p]\n",
    "    y = p_subset_df['y'].to_numpy()\n",
    "    X = p_subset_df.drop(columns=['y', 'pid', 'block_id', 'timestamp', 'elo', 'solved']).to_numpy()\n",
    "    all_X.extend(X)\n",
    "    all_y.extend(y)\n",
    "    all_P.extend(pd.Series([i] * len(X)))\n",
    "\n",
    "    #runCV(X, y, p, dtype)\n",
    "print('---------------------------------')\n",
    "print('---------------------------------')\n",
    "\n",
    "runCV(all_X, all_y, 'all', dtype)\n",
    "# run_merf(all_X, all_y, all_P, dtype)    \n",
    "\n",
    "print('---------------------------------')\n",
    "print('---------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runCV(X, y, pid, datatype):\n",
    " \n",
    "    MODELS = {\n",
    "        'RandomForestClassifier': {\n",
    "            'model': RandomForestClassifier(),\n",
    "            'gridparams': {\n",
    "                'n_estimators': [100, 200, 300, 500],\n",
    "                'max_depth': [None, 10, 20, 30],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'bootstrap': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'GradientBoostingClassifier': {\n",
    "            'model': GradientBoostingClassifier(),\n",
    "            'gridparams': {\n",
    "                'learning_rate': [0.1, 0.05, 0.01],\n",
    "                'n_estimators': [100, 200, 500],\n",
    "                'max_depth': [3, 5, 10],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "        },\n",
    "        'KNeighborsClassifier': {\n",
    "            'model': KNeighborsClassifier(),\n",
    "            'gridparams': {\n",
    "                'n_neighbors': range(1, 30),\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "            }\n",
    "        },\n",
    "        'AdaBoostClassifier': {\n",
    "            'model': AdaBoostClassifier(),\n",
    "            'gridparams': {\n",
    "                'n_estimators': [50, 100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 1.0]\n",
    "            }\n",
    "        },\n",
    "        'SVC': {\n",
    "            'model': SVC(),\n",
    "            'gridparams': {\n",
    "                'C': [0.1, 1, 10, 100],\n",
    "                'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
    "                'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE) # 5-Fold CV\n",
    "    reports = { model: [] for model in MODELS }\n",
    "    for modelName in MODELS:\n",
    "        model = MODELS[modelName]['model']\n",
    "        params = MODELS[modelName]['gridparams']\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=params, \n",
    "                                   cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        print(modelName)\n",
    "        print(\"Best parameters:\", grid_search.best_params_)\n",
    "        print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "        reports[model] = [grid_search.best_score_]\n",
    "\n",
    "    avgs = {model:np.mean(reports[model]) for model in reports}\n",
    "    max_name_length = max(len(model.__class__.__name__) for model in avgs)\n",
    "\n",
    "    # print best modelss sorted by avg f1 score\n",
    "    avgs = {k: v for k, v in sorted(avgs.items(), key=lambda item: item[1], reverse=True)}\n",
    "    for model, avg in avgs.items():\n",
    "        print(f\"{datatype} - pid - {pid} - {model.__class__.__name__:<{max_name_length}} - {avg:.3f}\")\n",
    "    \n",
    "    print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_merf(X, y, P, datatype):  \n",
    "    \n",
    "    MERF_REGRESSOR = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    P = pd.Series(P)  \n",
    "\n",
    "    n_splits = 3\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    indices = list(range(len(X)))\n",
    "\n",
    "    reports = []\n",
    "    for i, (train_indices, test_indices) in enumerate(kf.split(indices)):\n",
    "        print(f\"MERF i: {i}\" )\n",
    "        train_indices = train_indices.tolist()\n",
    "        test_indices = test_indices.tolist()\n",
    "        \n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "        P_train, P_test = P[train_indices], P[test_indices]\n",
    "        \n",
    "        Z_train = np.ones((len(X_train), 1))\n",
    "        Z_test = np.ones((len(X_test), 1))\n",
    "                    \n",
    "        mrf = MERF(MERF_REGRESSOR, max_iterations=MERF_MAX_ITER)        \n",
    "        mrf.fit(X_train, Z_train, P_train, y_train)\n",
    "        \n",
    "        preds = mrf.predict(X_test, Z_test, P_test)\n",
    "        \n",
    "        preds = [pred > 0.5 for pred in preds] # duh this isn't super great \n",
    "        print(y_test)\n",
    "        print(preds)\n",
    "        \n",
    "        report = classification_report(y_test, preds, output_dict=True)        \n",
    "        reports.append(report['macro avg']['f1-score'])\n",
    "    \n",
    "    print(f\"{datatype} - MERF macro f1-score average on test set for {n_splits}-fold cross-validation: {np.mean(reports)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
