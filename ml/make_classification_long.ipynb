{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file: study_p_5_5_psd_bp_notch_avgref.csv\n",
      "2a7ba24a - psd - 6881\n",
      "44dd5d31 - psd - 6254\n",
      "92511e53 - psd - 8668\n",
      "1bf79614 - psd - 5249\n",
      "cf88d785 - psd - 12210\n",
      "168dd1ac - psd - 12429\n",
      "7cc59678 - psd - 8327\n",
      "16230396 - psd - 7754\n",
      "5c1034cf - psd - 9044\n",
      "7848bec2 - psd - 5843\n",
      "2a7ba24a\n",
      "44dd5d31\n",
      "92511e53\n",
      "1bf79614\n",
      "cf88d785\n",
      "168dd1ac\n",
      "7cc59678\n",
      "16230396\n",
      "5c1034cf\n",
      "7848bec2\n",
      "---------------------------------\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [merf.py:307] Training GLL is -160454.75383509905 at iteration 1.\n",
      "INFO     [merf.py:307] Training GLL is -160665.8145211323 at iteration 2.\n",
      "INFO     [merf.py:307] Training GLL is -160686.86373086614 at iteration 3.\n",
      "INFO     [merf.py:307] Training GLL is -160798.39868076943 at iteration 4.\n",
      "INFO     [merf.py:307] Training GLL is -160979.63221557578 at iteration 5.\n",
      "INFO     [merf.py:307] Training GLL is -161048.37970965708 at iteration 6.\n",
      "INFO     [merf.py:307] Training GLL is -161044.69469096072 at iteration 7.\n",
      "INFO     [merf.py:307] Training GLL is -161091.51166000185 at iteration 8.\n",
      "INFO     [merf.py:307] Training GLL is -160938.27543620756 at iteration 9.\n",
      "INFO     [merf.py:307] Training GLL is -161038.355776976 at iteration 10.\n",
      "INFO     [merf.py:307] Training GLL is -161257.3200944365 at iteration 11.\n",
      "INFO     [merf.py:307] Training GLL is -161169.73650929728 at iteration 12.\n",
      "INFO     [merf.py:307] Training GLL is -161232.60865318374 at iteration 13.\n",
      "INFO     [merf.py:307] Training GLL is -161149.62421856466 at iteration 14.\n",
      "INFO     [merf.py:307] Training GLL is -161077.63422415894 at iteration 15.\n",
      "INFO     [merf.py:307] Training GLL is -161044.2501951557 at iteration 16.\n",
      "INFO     [merf.py:307] Training GLL is -161119.36398693445 at iteration 17.\n",
      "INFO     [merf.py:307] Training GLL is -161092.61108211498 at iteration 18.\n",
      "INFO     [merf.py:307] Training GLL is -161043.47340646177 at iteration 19.\n",
      "INFO     [merf.py:307] Training GLL is -161162.2128868735 at iteration 20.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mrf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mrussell/hcijs/ml/make_classification.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m all_P \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(all_P)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39m#runKFold(all_X, all_y, all_B, 'all', dtype)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m runKFold(all_X, all_y, all_B, \u001b[39m'\u001b[39;49m\u001b[39mall\u001b[39;49m\u001b[39m'\u001b[39;49m, dtype, merf\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, P\u001b[39m=\u001b[39;49mall_P)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/mrussell/hcijs/ml/make_classification.ipynb Cell 1\u001b[0m in \u001b[0;36mrunKFold\u001b[0;34m(X, y, B, pid, datatype, merf, P)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     Z_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39mlen\u001b[39m(X_test), \u001b[39m1\u001b[39m))                \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, Z_train, P_train, y_train)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     preds \u001b[39m=\u001b[39m mrf\u001b[39m.\u001b[39mpredict(X_test, Z_test, P_test)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     preds \u001b[39m=\u001b[39m [pred \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39mfor\u001b[39;00m pred \u001b[39min\u001b[39;00m preds] \u001b[39m# duh this isn't super great \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mrussell/hcijs/ml/make_classification.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mrf' is not defined"
     ]
    }
   ],
   "source": [
    "# merf psd 0.7742113806103438\n",
    "# merf after reref to avg mastoids 0.7436573207110183\n",
    "#psd - pid - all - KNeighborsClassifier          - 0.750\n",
    "\n",
    "#TODO: ADD OTHER REGRESSORS TO MERF. \n",
    "#TODO: ensure that we have balanced data per participant in training/testing. \n",
    "#TODO: see how hold-one-out participant training works; see if adding some training data per person works. \n",
    "\n",
    "# TODO ML: hold one out participant\n",
    "# TODO ML: collapse with extra features -> sd/min/max/quantiles?\n",
    "# TODO ML: validation set \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, \\\n",
    "                             AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "from merf import MERF\n",
    "from library import *\n",
    "\n",
    "MERF_MAX_ITER = 20\n",
    "\n",
    "#suppress undefined metric warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "#F_FMT = 'bp_notch_smooth_avgref.csv'\n",
    "\n",
    "Y_STYLE = 'elo'\n",
    "\n",
    "LOWER_QUANTILE = 0.25\n",
    "UPPER_QUANTILE = 0.75\n",
    "\n",
    "COLLAPSE = False\n",
    "\n",
    "# tried regressors: AdaBoostRegressor() -- 55\n",
    "MERF_REGRESSOR = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "# GaussianMixture() -> bad for everyone \n",
    "MODELS = [ RandomForestClassifier(random_state=RANDOM_STATE), svm.SVC(kernel='rbf'),\n",
    "           svm.SVC(kernel='linear'), svm.SVC(kernel='poly'), svm.SVC(kernel='sigmoid'),\n",
    "            KNeighborsClassifier(n_neighbors=3), AdaBoostClassifier(), GradientBoostingClassifier(),\n",
    "           GaussianNB(), GaussianProcessClassifier(), QuadraticDiscriminantAnalysis(), LinearDiscriminantAnalysis() ]\n",
    "\n",
    "print(f\"loading file: {DBFNAME.split('.csv')[0]}_psd_{FILTNAME}\")\n",
    "psd_df = pd.read_csv(f\"{DBFNAME.split('.csv')[0]}_psd_{FILTNAME}\", dtype = {'pid': str})\n",
    "#raw_df = pd.read_csv(f\"{DBFNAME.split('.csv')[0]}_raw_{FILTNAME}\", dtype = {'pid': str})\n",
    "\n",
    "# drop all rows that have 'nan' in pid\n",
    "psd_df = psd_df[psd_df['pid'].notna()]\n",
    "#raw_df = raw_df[raw_df['pid'].notna()]\n",
    "\n",
    "PIDS = psd_df['pid'].unique()\n",
    "\n",
    "# side effect - block_id is now globally unique. \n",
    "def extract_features(df, collapse_blocks=True):\n",
    "    if collapse_blocks:\n",
    "        df = df.groupby(['pid', 'block_id']).mean().reset_index()\n",
    "      \n",
    "    p_dfs = {}\n",
    "    unique_id = 0\n",
    "    for pid in df['pid'].unique():\n",
    "        p_df = df[df['pid'] == pid].copy().reset_index(drop=True)\n",
    "        \n",
    "        for block_id in p_df['block_id'].unique():\n",
    "            p_df.loc[p_df['block_id'] == block_id, 'block_id'] = unique_id\n",
    "            unique_id += 1\n",
    "\n",
    "        lower = p_df['elo'].quantile(LOWER_QUANTILE)\n",
    "        upper = p_df['elo'].quantile(UPPER_QUANTILE)\n",
    "\n",
    "        if Y_STYLE == 'elo':            \n",
    "            p_df = p_df[(p_df['elo'] <= lower) | (p_df['elo'] >= upper)].reset_index(drop=True)\n",
    "            p_df['y'] = p_df['elo'] > lower\n",
    "        else:            \n",
    "            p_df['y'] = p_df['solved']\n",
    "\n",
    "        p_dfs[pid] = p_df\n",
    "    \n",
    "    return p_dfs\n",
    "    \n",
    "ALL_DFS = {\n",
    "            #'raw': extract_features(raw_df), \n",
    "            'psd': extract_features(psd_df, collapse_blocks=COLLAPSE)\n",
    "        }\n",
    "\n",
    "for p in PIDS:\n",
    "    for dtype in ALL_DFS:\n",
    "        print(f\"{p} - {dtype} - {len(ALL_DFS[dtype][p])}\")\n",
    "\n",
    "for dtype in ALL_DFS:\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    all_P = []\n",
    "    all_B = []\n",
    "    for i, p in enumerate(PIDS):   \n",
    "        print(p)     \n",
    "        p_subset_df = ALL_DFS[dtype][p]    \n",
    "        B = p_subset_df['block_id'].to_numpy()\n",
    "        y = p_subset_df['y'].to_numpy()    \n",
    "        X = p_subset_df.drop(columns=['y', 'pid', 'block_id', 'timestamp', 'elo', 'solved']).to_numpy()\n",
    "        all_X.extend(X)\n",
    "        all_y.extend(y)\n",
    "        all_P.extend(pd.Series([i] * len(X)))\n",
    "        all_B.extend(B)\n",
    "\n",
    "        #runKFold(X, y, B, p, dtype)\n",
    "    print('---------------------------------')\n",
    "    print('---------------------------------')\n",
    "\n",
    "    all_X = np.array(all_X)\n",
    "    all_y = np.array(all_y)\n",
    "    all_P = pd.Series(all_P)\n",
    "    #runKFold(all_X, all_y, all_B, 'all', dtype)\n",
    "    runKFold(all_X, all_y, all_B, 'all', dtype, merf=True, P=all_P)\n",
    "    print('---------------------------------')\n",
    "    print('---------------------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "runKFold \n",
    "inputs: \n",
    "    X: brain data\n",
    "    y: labels\n",
    "    B: block ids\n",
    "    pid: participant id\n",
    "\"\"\"\n",
    "\n",
    "def runKFold(X, y, B, pid, datatype, merf=False, P=None):\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    # unique block ids for the participant\n",
    "    b_ids = np.unique(B)\n",
    "\n",
    "    # this is janky but we can remove the other function\n",
    "    if merf:\n",
    "        MODELS = [MERF(MERF_REGRESSOR, max_iterations=MERF_MAX_ITER)]\n",
    "        reports = { \"MERF\": [] }\n",
    "    else:\n",
    "        reports = { model: [] for model in MODELS }\n",
    "   \n",
    "    for i, (train_b_id_idxs, test_b_id_idxs) in enumerate(kf.split(b_ids)):        \n",
    "        \n",
    "        # print(train_b_ids)\n",
    "        # print(test_b_ids)\n",
    "        # print('-------------------')\n",
    "        train_indices = [i for i in range(len(B)) if B[i] in b_ids[train_b_id_idxs]]\n",
    "        test_indices = [i for i in range(len(B)) if B[i] in b_ids[test_b_id_idxs]]   \n",
    "        \n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "        for model in MODELS:\n",
    "            if merf:\n",
    "                P_train, P_test = P[train_indices], P[test_indices]\n",
    "                Z_train = np.ones((len(X_train), 1))\n",
    "                Z_test = np.ones((len(X_test), 1))                \n",
    "                model.fit(X_train, Z_train, P_train, y_train)\n",
    "                \n",
    "                preds = model.predict(X_test, Z_test, P_test)\n",
    "                preds = [pred > 0.5 for pred in preds] # duh this isn't super great \n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                preds = model.predict(X_test)\n",
    "        \n",
    "            report = classification_report(y_test, preds, output_dict=True)\n",
    "            reports[model].append(report['macro avg']['f1-score'])\n",
    "    \n",
    "    avgs = {model:np.mean(reports[model]) for model in reports}\n",
    "    max_name_length = max(len(model.__class__.__name__) for model in avgs)\n",
    "\n",
    "    # print sorted in desceding classification order\n",
    "    avgs = {k: v for k, v in sorted(avgs.items(), key=lambda item: item[1], reverse=True)}\n",
    "    for model, avg in avgs.items():\n",
    "        print(f\"{datatype} - pid - {pid} - {model.__class__.__name__:<{max_name_length}} - {avg:.3f}\")\n",
    "    \n",
    "    print('---------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
